{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text analysis\n",
    "\n",
    "1. Determine bias of the input article\n",
    "2. Determine direction (left/right)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BIAS DETECTION:\n",
    "    - detect biased words, compute an index\n",
    "    - Get sentiment on various topics, known to differ from left to right political view (sentiment analysis on paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the sample article\n",
    "article = open('sample_article.txt', 'r').read()\n",
    "\n",
    "# Convert to single long string\n",
    "article = article.replace('\\'', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Virginia mom says activists threatened to  curb stomp  her for speaking out against school curriculum\\n This is murder,  Loudoun County parent Alisha Brand told  Fox & Friends \\n\\nParents in Loudoun County, Virginia, say they have become targets of violent threats on social media for speaking out against the school district s LGBTQ agenda.\\n\\n\"They said that they wanted to curb stomp me,\" Loudoun County mom and Army of Parents co-founder Alisha Brand told \"Fox & Friends\" Friday of threats made on the \"Loudoun Love Warriors\" Facebook page.\\n\\nBrand said her organization, which she described as a 501(c)(4) that advocates for excellence in education, school safety and parental rights, has made activists online \"very angry,\" leading to \"threats of death.\"\\n\\n\"I m not sure if your audience is aware of the violent nature of curb stomping, but what it does entail is grabbing somebody by the back of the head, forcing their mouth open, pushing them down to the ground with their face on the cement, their mouth around the curb, and then somebody else stomping on the back of their head,\" she continued. \\n\"This is murder, it s a felony, and this is what I was threatened with by these activists who are tied to our political candidates.\"\\n\\nThe \"Loudoun Love Warriors\" group includes members who appear to be associated with Loudoun County Commonwealth’s Attorney Buta Biberaj, County Supervisor Juli Briskman, School Board Chair Ian Serotkin, school board member Brenda Sheridan, school board member Atoosa Reaser, school board member Erika Ogedegbe, school board candidate Anne Donohue, sheriff candidate Craig Buckley, and Chair Phyllis Randall. None of these elected officials personally made any threats.\\n\\nLoudoun County resident Mark Winn told WJLA he learned of messages on the group threatening his life and livelihood after he addressed the school board in Dec. 2022.\\n\\n\"[LGBT] behaviors should never have been promoted, taught, or encouraged in the schools that you oversee,\" he said at the meeting. \"Get back to reading, writing and arithmetic and quit grooming and pimping.\"\\n\\nScott Mineo, another Loudoun County parent, told WJLA that activists \"went after\" his job. \\n\\n\"They referred me to the FBI, IRS, and DHS all because they don’t like my opinion,\" he said.\\n\"They re probably going to sit back and celebrate the fact that I m unemployed. I m having a hard time finding a job. And who knows what s next with the IRS and the FBI? I don t know. But they ve done more than just put me out of a job. It s impacting my family, my kids.\"\\n\\nBrand said she s taken the issue to the team of House Judiciary Committee Chair Rep. Jim Jordan, R-Ohio, hoping for an investigation into the threats and accountability. She also called for legislation to protect parents who advocate for their children in public forums like school board meetings.\\n\\n\"This is a First Amendment right,\" Bland said.\\nA spokesperson for the Loudoun County Public Schools directed Fox News Digital to statements that some Loudoun County officials have made in public regarding the controversy. \\n\\n\"Violent threats are never acceptable and at times can be criminal. I personally condemn all violent language and my office will be investigating whether a crime was committed. Due to the possibility of a criminal investigation, I can not comment further at this time,\" Loudoun County Commonwealth’s Attorney Buta Biberaj said in response to the news. '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required NLTK data\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = re.sub(r'[^\\w\\s]', '', \" \".join(tokens))\n",
    "    tokens = tokens.split(\" \")\n",
    "    stop_words = stopwords.words('english')\n",
    "    tokens = [token.lower() for token in tokens if token.lower() not in stop_words and len(token) > 0]\n",
    "\n",
    "    # Lemmatize tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_tokens = preprocess_text(article)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test sentiment analysis with chatGPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'openai_api_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-459c527b1a07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mopenapi_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"openai_api_key\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mopenai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopenapi_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'openai_api_key'"
     ]
    }
   ],
   "source": [
    "openapi_key = open(\"openai_api_key\", \"r\").read().strip()\n",
    "openai.api_key = openapi_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(topic: str, text: str) -> str:\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=f\"Decide whether text's sentiment is positive, neutral, or negative based on {topic}.\\n\\n text: {text} \\\"\\nSentiment:\",\n",
    "    temperature=0,\n",
    "    max_tokens=100,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.5,\n",
    "    presence_penalty=0.0\n",
    "    )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virginia',\n",
       " 'mom',\n",
       " 'say',\n",
       " 'activist',\n",
       " 'threatened',\n",
       " 'curb',\n",
       " 'stomp',\n",
       " 'speaking',\n",
       " 'school',\n",
       " 'curriculum',\n",
       " 'murder',\n",
       " 'loudoun',\n",
       " 'county',\n",
       " 'parent',\n",
       " 'alisha',\n",
       " 'brand',\n",
       " 'told',\n",
       " 'fox',\n",
       " 'friend',\n",
       " 'parent',\n",
       " 'loudoun',\n",
       " 'county',\n",
       " 'virginia',\n",
       " 'say',\n",
       " 'become',\n",
       " 'target',\n",
       " 'violent',\n",
       " 'threat',\n",
       " 'social',\n",
       " 'medium',\n",
       " 'speaking',\n",
       " 'school',\n",
       " 'district',\n",
       " 'lgbtq',\n",
       " 'agenda',\n",
       " 'said',\n",
       " 'wanted',\n",
       " 'curb',\n",
       " 'stomp',\n",
       " 'loudoun',\n",
       " 'county',\n",
       " 'mom',\n",
       " 'army',\n",
       " 'parent',\n",
       " 'cofounder',\n",
       " 'alisha',\n",
       " 'brand',\n",
       " 'told',\n",
       " 'fox',\n",
       " 'friend',\n",
       " 'friday',\n",
       " 'threat',\n",
       " 'made',\n",
       " 'loudoun',\n",
       " 'love',\n",
       " 'warrior',\n",
       " 'facebook',\n",
       " 'page',\n",
       " 'brand',\n",
       " 'said',\n",
       " 'organization',\n",
       " 'described',\n",
       " '501',\n",
       " 'c',\n",
       " '4',\n",
       " 'advocate',\n",
       " 'excellence',\n",
       " 'education',\n",
       " 'school',\n",
       " 'safety',\n",
       " 'parental',\n",
       " 'right',\n",
       " 'made',\n",
       " 'activist',\n",
       " 'online',\n",
       " 'angry',\n",
       " 'leading',\n",
       " 'threat',\n",
       " 'death',\n",
       " 'sure',\n",
       " 'audience',\n",
       " 'aware',\n",
       " 'violent',\n",
       " 'nature',\n",
       " 'curb',\n",
       " 'stomping',\n",
       " 'entail',\n",
       " 'grabbing',\n",
       " 'somebody',\n",
       " 'back',\n",
       " 'head',\n",
       " 'forcing',\n",
       " 'mouth',\n",
       " 'open',\n",
       " 'pushing',\n",
       " 'ground',\n",
       " 'face',\n",
       " 'cement',\n",
       " 'mouth',\n",
       " 'around',\n",
       " 'curb',\n",
       " 'somebody',\n",
       " 'else',\n",
       " 'stomping',\n",
       " 'back',\n",
       " 'head',\n",
       " 'continued',\n",
       " 'murder',\n",
       " 'felony',\n",
       " 'threatened',\n",
       " 'activist',\n",
       " 'tied',\n",
       " 'political',\n",
       " 'candidate',\n",
       " 'loudoun',\n",
       " 'love',\n",
       " 'warrior',\n",
       " 'group',\n",
       " 'includes',\n",
       " 'member',\n",
       " 'appear',\n",
       " 'associated',\n",
       " 'loudoun',\n",
       " 'county',\n",
       " 'commonwealth',\n",
       " 'attorney',\n",
       " 'buta',\n",
       " 'biberaj',\n",
       " 'county',\n",
       " 'supervisor',\n",
       " 'juli',\n",
       " 'briskman',\n",
       " 'school',\n",
       " 'board',\n",
       " 'chair',\n",
       " 'ian',\n",
       " 'serotkin',\n",
       " 'school',\n",
       " 'board',\n",
       " 'member',\n",
       " 'brenda',\n",
       " 'sheridan',\n",
       " 'school',\n",
       " 'board',\n",
       " 'member',\n",
       " 'atoosa',\n",
       " 'reaser',\n",
       " 'school',\n",
       " 'board',\n",
       " 'member',\n",
       " 'erika',\n",
       " 'ogedegbe',\n",
       " 'school',\n",
       " 'board',\n",
       " 'candidate',\n",
       " 'anne',\n",
       " 'donohue',\n",
       " 'sheriff',\n",
       " 'candidate',\n",
       " 'craig',\n",
       " 'buckley',\n",
       " 'chair',\n",
       " 'phyllis',\n",
       " 'randall',\n",
       " 'none',\n",
       " 'elected',\n",
       " 'official',\n",
       " 'personally',\n",
       " 'made',\n",
       " 'threat',\n",
       " 'loudoun',\n",
       " 'county',\n",
       " 'resident',\n",
       " 'mark',\n",
       " 'winn',\n",
       " 'told',\n",
       " 'wjla',\n",
       " 'learned',\n",
       " 'message',\n",
       " 'group',\n",
       " 'threatening',\n",
       " 'life',\n",
       " 'livelihood',\n",
       " 'addressed',\n",
       " 'school',\n",
       " 'board',\n",
       " 'dec',\n",
       " '2022',\n",
       " 'lgbt',\n",
       " 'behavior',\n",
       " 'never',\n",
       " 'promoted',\n",
       " 'taught',\n",
       " 'encouraged',\n",
       " 'school',\n",
       " 'oversee',\n",
       " 'said',\n",
       " 'meeting',\n",
       " 'get',\n",
       " 'back',\n",
       " 'reading',\n",
       " 'writing',\n",
       " 'arithmetic',\n",
       " 'quit',\n",
       " 'grooming',\n",
       " 'pimping',\n",
       " 'scott',\n",
       " 'mineo',\n",
       " 'another',\n",
       " 'loudoun',\n",
       " 'county',\n",
       " 'parent',\n",
       " 'told',\n",
       " 'wjla',\n",
       " 'activist',\n",
       " 'went',\n",
       " 'job',\n",
       " 'referred',\n",
       " 'fbi',\n",
       " 'irs',\n",
       " 'dhs',\n",
       " 'like',\n",
       " 'opinion',\n",
       " 'said',\n",
       " 'probably',\n",
       " 'going',\n",
       " 'sit',\n",
       " 'back',\n",
       " 'celebrate',\n",
       " 'fact',\n",
       " 'unemployed',\n",
       " 'hard',\n",
       " 'time',\n",
       " 'finding',\n",
       " 'job',\n",
       " 'know',\n",
       " 'next',\n",
       " 'irs',\n",
       " 'fbi',\n",
       " 'know',\n",
       " 'done',\n",
       " 'put',\n",
       " 'job',\n",
       " 'impacting',\n",
       " 'family',\n",
       " 'kid',\n",
       " 'brand',\n",
       " 'said',\n",
       " 'taken',\n",
       " 'issue',\n",
       " 'team',\n",
       " 'house',\n",
       " 'judiciary',\n",
       " 'committee',\n",
       " 'chair',\n",
       " 'rep',\n",
       " 'jim',\n",
       " 'jordan',\n",
       " 'rohio',\n",
       " 'hoping',\n",
       " 'investigation',\n",
       " 'threat',\n",
       " 'accountability',\n",
       " 'also',\n",
       " 'called',\n",
       " 'legislation',\n",
       " 'protect',\n",
       " 'parent',\n",
       " 'advocate',\n",
       " 'child',\n",
       " 'public',\n",
       " 'forum',\n",
       " 'like',\n",
       " 'school',\n",
       " 'board',\n",
       " 'meeting',\n",
       " 'first',\n",
       " 'amendment',\n",
       " 'right',\n",
       " 'bland',\n",
       " 'said',\n",
       " 'spokesperson',\n",
       " 'loudoun',\n",
       " 'county',\n",
       " 'public',\n",
       " 'school',\n",
       " 'directed',\n",
       " 'fox',\n",
       " 'news',\n",
       " 'digital',\n",
       " 'statement',\n",
       " 'loudoun',\n",
       " 'county',\n",
       " 'official',\n",
       " 'made',\n",
       " 'public',\n",
       " 'regarding',\n",
       " 'controversy',\n",
       " 'violent',\n",
       " 'threat',\n",
       " 'never',\n",
       " 'acceptable',\n",
       " 'time',\n",
       " 'criminal',\n",
       " 'personally',\n",
       " 'condemn',\n",
       " 'violent',\n",
       " 'language',\n",
       " 'office',\n",
       " 'investigating',\n",
       " 'whether',\n",
       " 'crime',\n",
       " 'committed',\n",
       " 'due',\n",
       " 'possibility',\n",
       " 'criminal',\n",
       " 'investigation',\n",
       " 'comment',\n",
       " 'time',\n",
       " 'loudoun',\n",
       " 'county',\n",
       " 'commonwealth',\n",
       " 'attorney',\n",
       " 'buta',\n",
       " 'biberaj',\n",
       " 'said',\n",
       " 'response',\n",
       " 'news']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = get_sentiment(\"right wing agenda\", \" \".join(lemmatized_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7FjbB4m09ldDxnDPOj93bvxEiKrLg at 0x1d6f6124220> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" Negative\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1683984557,\n",
       "  \"id\": \"cmpl-7FjbB4m09ldDxnDPOj93bvxEiKrLg\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 1,\n",
       "    \"prompt_tokens\": 427,\n",
       "    \"total_tokens\": 428\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virginia mom say activist threatened curb stomp speaking school curriculum murder loudoun county parent alisha brand told fox friend parent loudoun county virginia say become target violent threat social medium speaking school district lgbtq agenda said wanted curb stomp loudoun county mom army parent cofounder alisha brand told fox friend'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \" \".join(lemmatized_tokens[:50])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flag text based on words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_words = open(\"biasDataset.csv\", \"r\").read().split(\"\\n\")\n",
    "bias_words = list(map(lambda x: x.lower(), bias_words))\n",
    "bias_words.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for occurences in the original article\n",
    "#bias_words_in_article = list(filter(lambda x: x.strip() in article.lower().strip(), bias_words))\n",
    "#preprocessed = preprocess_text(\" \".join(bias_words))\n",
    "#bias_words_in_article_processed = list(filter(lambda x: x.strip() in \" \".join(lemmatized_tokens), bias_words))\n",
    "\n",
    "# Create union\n",
    "bias_words_in_article = list(set(bias_words_in_article + bias_words_in_article_processed))\n",
    "bias_words_in_article = list(map(lambda x: x.strip(), bias_words_in_article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forcing', 'raged', 'investigation']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_words_in_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raged', 'forcing', 'investigation ', '']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_words_in_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url_embedded = \"https://openai-api.meetings.bio/api/openai/embeddings\"\n",
    "url_completion = \"https://openai-api.meetings.bio/api/openai/chat/completions\"\n",
    "model = \"gpt-3.5-turbo\" #\"text-embedding-ada-002\" # \n",
    "token = \"MolDNdTf1iTLl4aWEe1eBgYOtecJ5m\"#open(\"gpt4_token\", \"r\").read().strip()\n",
    "\n",
    "class GPT4:\n",
    "   def __init__(self, url, token, model=\"gpt-3.5-turbo\"):\n",
    "      self.model = model\n",
    "      self.url = url\n",
    "      self.token = token\n",
    "      \n",
    "   def post_request(self, prompt, role=\"user\"):\n",
    "      \n",
    "      if model == \"gpt-3.5-turbo\":\n",
    "         response = requests.post(\n",
    "            self.url,\n",
    "            headers={\"Authorization\": f\"Bearer {self.token}\"},\n",
    "            json={\n",
    "             \"model\": model,\n",
    "             \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            },\n",
    "         )\n",
    "      else:\n",
    "         response = requests.post(\n",
    "            self.url,\n",
    "            headers={\"Authorization\": f\"Bearer {self.token}\"},\n",
    "           json={\n",
    "               \"model\": model,\n",
    "               \"input\": prompt,\n",
    "            },\n",
    "         )\n",
    "   \n",
    "      return response\n",
    "\n",
    "   def print_response(self, response):\n",
    "      if response.ok:\n",
    "         if model == \"gpt-3.5-turbo\":\n",
    "            print(response.json()[\"choices\"][0][\"message\"][\"content\"])\n",
    "         else:\n",
    "            print(response.json())\n",
    "      else:\n",
    "         print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lemmatized_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-493b8750461a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGPT4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_completion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Determine the political bias of the following text - return a score on the interval [-1, 1], where -1 means strong leftism and 1 means strong rightism: {' '.join(lemmatized_tokens)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mgpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lemmatized_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "gpt = GPT4(url_completion, token, model)\n",
    "res = gpt.post_request(f\"Determine the political bias of the following text - return a score on the interval [-1, 1], where -1 means strong leftism and 1 means strong rightism: {' '.join(lemmatized_tokens)}\")\n",
    "gpt.print_response(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_classification import get_biased_words_frequency\n",
    "\n",
    "url_embedded = \"https://openai-api.meetings.bio/api/openai/embeddings\"\n",
    "url_completion = \"https://openai-api.meetings.bio/api/openai/chat/completions\"\n",
    "model = \"gpt-3.5-turbo\" #\"text-embedding-ada-002\" # \n",
    "token = \"MolDNdTf1iTLl4aWEe1eBgYOtecJ5m\"#open(\"gpt4_token\", \"r\").read().strip()\n",
    "bias_words = \"biasDataset.csv\"\n",
    "democrat_bias_words = \"democratBias.csv\"\n",
    "republican_bias_words = \"republicanBias.csv\"\n",
    "\n",
    "class BiasAssesment:\n",
    "    '''\n",
    "        - democrats \n",
    "        + republicans\n",
    "    '''\n",
    "    def __init__(self, article, frequencyWeightMultiMax = 1, frequencyDemRepSumMax = 1, sentimentSumMax = 1, susceptibilityMultiMax = 1, \n",
    "                chatGPTSumMax = 1):\n",
    "        #we multiply these\n",
    "        self.frequencyWeightMultiMax = frequencyWeightMultiMax\n",
    "        self.susceptibilityMultiMax = susceptibilityMultiMax\n",
    "\n",
    "        #we add these\n",
    "        self.frequencyDemRepSumMax = frequencyDemRepSumMax\n",
    "        self.sentimentSumMax = sentimentSumMax\n",
    "        self.chatGPTSumMax = chatGPTSumMax\n",
    "\n",
    "        indexMax = (frequencyDemRepSumMax + sentimentSumMax + chatGPTSumMax)*frequencyWeightMultiMax*susceptibilityMultiMax # če bodo vrednosti Multi manjše kot 1 se ne pomnoži za računanje indexMax\n",
    "\n",
    "\n",
    "        self.article = article\n",
    "\n",
    "        self.gpt = GPT4(url_completion, token, model)\n",
    "\n",
    "\n",
    "    def frequencyWeight(self):\n",
    "        '''\n",
    "            Calculates the frequency weight\n",
    "        '''\n",
    "        weightsMax1 = 1\n",
    "        biased_freq = get_biased_words_frequency(self.article, bias_words)\n",
    "        return(biased_freq*weightsMax1)\n",
    "\n",
    "    def susceptibilityMulti(self):\n",
    "        return(0)\n",
    "\n",
    "    def frequencyDemRepSum(self):\n",
    "        '''\n",
    "            Calculates the frequency weight by coadding negative democrat and positive republican frequency weights\n",
    "        '''\n",
    "        weightsMax3 = 1\n",
    "        biased_freq_demo = get_biased_words_frequency(self.article, democrat_bias_words)\n",
    "        biased_freq_rep = get_biased_words_frequency(self.article, republican_bias_words)\n",
    "        return((biased_freq_rep - biased_freq_demo)*weightsMax3)\n",
    "\n",
    "    def sentimentSum(self):\n",
    "        return(0)\n",
    "\n",
    "    def chatGPTSum(self):\n",
    "        return(0)\n",
    "    \n",
    "    def indexCalculating(self): \n",
    "        '''\n",
    "            Calculates the political bias index\n",
    "        '''\n",
    "        return ((self.frequencyDemRepSum()+ self.sentimentSum() + self.chatGPTSum())*self.frequencyWeight()*self.susceptibilityMulti())/self.indexMax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "filter expected 2 arguments, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-4c50f2d3942b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"sample_article.txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbias_assesment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBiasAssesment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_assesment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexCalculating\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-98-2ce38867ee35>\u001b[0m in \u001b[0;36mindexCalculating\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mCalculates\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpolitical\u001b[0m \u001b[0mbias\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         '''\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrequencyDemRepSum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentimentSum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchatGPTSum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrequencyWeight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msusceptibilityMulti\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexMax\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-98-2ce38867ee35>\u001b[0m in \u001b[0;36mfrequencyDemRepSum\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m         '''\n\u001b[0;32m     50\u001b[0m         \u001b[0mweightsMax3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mbiased_freq_demo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_biased_words_frequency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marticle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdemocrat_bias_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mbiased_freq_rep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_biased_words_frequency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marticle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepublican_bias_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbiased_freq_rep\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbiased_freq_demo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mweightsMax3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jan\\Documents\\Projects\\joe-bias\\text_classification.py\u001b[0m in \u001b[0;36mget_biased_words_frequency\u001b[1;34m(article, bias_words)\u001b[0m\n\u001b[0;32m     77\u001b[0m     '''\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mlistBias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: filter expected 2 arguments, got 1"
     ]
    }
   ],
   "source": [
    "\n",
    "f = \"sample_article.txt\"\n",
    "bias_assesment = BiasAssesment(f)\n",
    "print(bias_assesment.indexCalculating())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import math\n",
    "\n",
    "def get_biased_words_frequency(article, bias_words):\n",
    "    '''\n",
    "        Returns a dictionary of biased words and their frequencies\n",
    "    '''\n",
    "    with open(article, 'r') as f:\n",
    "        text = f.read()\n",
    "    with open(bias_words, 'r') as g:\n",
    "        listBias = g.read()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    freq_dist = nltk.FreqDist([word for word in tokens if word in listBias])\n",
    "    freq_dist_all = nltk.FreqDist(tokens)\n",
    "    frequency = sum(freq_dist.values())/(sum(freq_dist_all.values())*math.sqrt(len(listBias)))\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004370099858424613\n"
     ]
    }
   ],
   "source": [
    "file = \"sample_article.txt\"\n",
    "file1 = \"biasDataset.csv\"\n",
    "print(get_biased_words_frequency(file, file1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "virginia mom say activist threatened curb stomp speaking school curriculum murder loudoun county parent alisha brand told fox friend parent loudoun county virginia say become target violent threat social medium speaking school district lgbtq agenda said wanted curb stomp loudoun county mom army parent cofounder alisha brand told fox friend\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(lemmatized_tokens[:50]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joe_bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
